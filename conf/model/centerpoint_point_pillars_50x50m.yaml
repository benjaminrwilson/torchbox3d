##########################################################################
# CenterPoint                                                            #
##########################################################################

# The Centerpoint architecture configuration file.

# This consists of three main components:
# backbone - 3D processing portion of the network
# neck - 2D processing portion following 3D feature extraction
# head - Classification / regression, etc. This portion of the network is task specific.

name: "centerpoint"

arch_cfg:
  _target_: torchbox3d.nn.arch.centerpoint.CenterPoint

  tasks_cfg:
    # Define tasks here. Each task corresponds to a detection "head".
    # Typically, similar classes are placed together.
    # There are many different ways one could define "similarity"; however,
    # one common way is by size.

    # Each class should have a unique integer key. Additionally,
    # the task keys should be contiguous (e.g., 0, 1, 2, ...).

    0: ["REGULAR_VEHICLE"]

    1: [
      "PEDESTRIAN",
      "BICYCLIST",
      "MOTORCYCLIST",
      "WHEELED_RIDER",
    ]

    2: [
      "BOLLARD",
      "CONSTRUCTION_CONE",
      "SIGN",
      "CONSTRUCTION_BARREL",
      "STOP_SIGN",
      "MOBILE_PEDESTRIAN_CROSSING_SIGN",
    ]

    3: [
      "LARGE_VEHICLE",
      "BUS",
      "BOX_TRUCK",
      "TRUCK",
      "VEHICULAR_TRAILER",
      "TRUCK_CAB",
      "SCHOOL_BUS",
      "ARTICULATED_BUS",
      "MESSAGE_BOARD_TRAILER",
    ]

    4: [
      "BICYCLE",
      "MOTORCYCLE",
      "WHEELED_DEVICE",
      "WHEELCHAIR",
      "STROLLER",
    ]

    5: [
      "DOG",
    ]

  network_stride: 4
  pct_start: 0.4
  div_factor: 10.0
  max_k: 100
  train_log_freq: 10
  val_log_freq: 10

  devices: ${trainer.devices}
  lr: ${lr}

  epochs: ${trainer.max_epochs}

  src_dir: ${src_dir}
  dst_dir: ${dst_dir}

  batch_size: ${batch_size}
  debug: ${debug}

  ##########################################################################
  # TRANSFORMS                                                             #
  ##########################################################################

  train_transforms_cfg:
    voxelize:
      _target_: torchbox3d.math.transforms.voxelize.Voxelize

      resolution_m_per_cell: ${model.arch_cfg.backbone_cfg.resolution_m_per_cell}
      min_range_m: ${model.arch_cfg.backbone_cfg.min_range_m}
      max_range_m: ${model.arch_cfg.backbone_cfg.max_range_m}
      voxelization_type: ${model.arch_cfg.backbone_cfg.voxelization_type}

    splatter_heatmap:
      _target_: torchbox3d.math.transforms.splatter_heatmap.SplatterHeatmap  # Mapping to Python class for `hydra`.
      
      tasks_cfg: ${dataset.tasks_cfg}  # Task mapping. Maps unique integers to lists of target classes.
      network_stride: ${model.arch_cfg.network_stride}  # Spatial downsampling factor between input resolution and output resolution.
      dataset_name: ${dataset.name}

  # Validation transforms.
  val_transforms_cfg:
    voxelize: ${dataset.train_transforms_cfg.voxelize}
    splatter_heatmap: ${dataset.train_transforms_cfg.splatter_heatmap}

  # Test transforms.
  test_transforms_cfg:
    voxelize: ${model.arch_cfg.train_transforms_cfg.voxelize}
    splatter_heatmap: ${model.arch_cfg.train_transforms_cfg.splatter_heatmap}

  ##########################################################################
  # BACKBONE                                                               #
  ##########################################################################

  backbone_cfg:
    _target_: torchbox3d.nn.backbones.point_pillars.PointPillars
    name: pointpillars
    dim_in: 4  # Number of input dimensions
    resolution_m_per_cell: [0.4, 0.4, 10.0]
    min_range_m: [-25.6, -25.6, -5.0]
    max_range_m: [25.6, 25.6, 5.0]
    voxelization_type: concatenate

  ##########################################################################
  # NECK                                                                   #
  ##########################################################################

  neck_cfg:
    _target_: torchbox3d.nn.nets.resnet.ResNet
    name: resnet
    in_channels: 64  # Number of input channels.
    layer_nums: [3, 5, 5]  # Number of downsampling / upsampling layers.
    down_strides: [2, 2, 2]  # Stride per downsampling layer.
    down_planes: [64, 128, 256]  # Number of filters per downsampling layer.
    up_strides: [0.5, 1, 2]  # Stride per upsampling layer.
    num_up_filters: [128, 128, 128]  # Number of filters per upsampling layer.

  ##########################################################################
  # HEAD                                                                   #
  ##########################################################################

  head_cfg:
    # Center Head Configuration.
    _target_: torchbox3d.nn.heads.center.CenterHead
    tasks_cfg: ${dataset.tasks_cfg}  # Task mapping. Maps unique integers to lists of target classes.
    in_channels: 384  # Number of input channels.
    weight: 0.25  # Regression loss weighting.
    common_heads:  # Defines the output of the task heads.
      center: [2, 2]
      height: [1, 2]
      dim: [3, 2]
      rot: [2, 2]
    task_in_channels: 64  # Task head channels.
